{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab21f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('FrozenLake-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c057a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class ConcatObs(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = \\\n",
    "            spaces.Box(low=0, high=255, shape=((k,) + shp), dtype=env.observation_space.dtype)\n",
    "\n",
    "\n",
    "def reset(self):\n",
    "    ob = self.env.reset()\n",
    "    for _ in range(self.k):\n",
    "        self.frames.append(ob)\n",
    "    return self._get_ob()\n",
    "\n",
    "def step(self, action):\n",
    "    ob, reward, done, info = self.env.step(action)\n",
    "    self.frames.append(ob)\n",
    "    return self._get_ob(), reward, done, info\n",
    "\n",
    "def _get_ob(self):\n",
    "    return np.array(self.frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "74da6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_env = ConcatObs(env, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16796efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "class ObservationWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def observation(self, obs):\n",
    "        # Normalise observation by 255\n",
    "        return obs / 255.0\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, reward):\n",
    "        # Clip reward between 0 to 1\n",
    "        return np.clip(reward, 0, 1)\n",
    "    \n",
    "class ActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def action(self, action):\n",
    "        if action == 3:\n",
    "            return random.choice([0,1,2])\n",
    "        else:\n",
    "            return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51b719f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All checks passed\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "wrapped_env = ObservationWrapper(RewardWrapper(ActionWrapper(env)))\n",
    "\n",
    "obs = wrapped_env.reset()\n",
    "\n",
    "for step in range(100):\n",
    "    action = wrapped_env.action_space.sample()\n",
    "    obs, reward, done, info = wrapped_env.step(action)\n",
    "    \n",
    "    # Raise a flag if values have not been vectorised properly\n",
    "#    if (obs > 1.0).any() or (obs < 0.0).any():\n",
    "   #    print(\"Max and min value of observations out of range\")\n",
    "    \n",
    "    # Raise a flag if reward has not been clipped.\n",
    "    if reward < 0.0 or reward > 1.0:\n",
    "     #   assert False, \"Reward out of bounds\"\n",
    "    \n",
    "    # Check the rendering if the slider moves to the left.\n",
    "    wrapped_env.render()\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "\n",
    "wrapped_env.close()\n",
    "\n",
    "print(\"All checks passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc58fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wrapped Env:\", wrapped_env)\n",
    "print(\"Unwrapped Env\", wrapped_env.unwrapped)\n",
    "print(\"Getting the meaning of actions\", wrapped_env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e76ff5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Discrete(16)\n",
      "The action space: Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "# Observation and action space \n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space))\n",
    "print(\"The action space: {}\".format(action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b4519fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "env.render(mode = \"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5eec82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74184a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "# Number of steps you run the agent for \n",
    "num_steps = 100\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    # take random action, but you can also do something more intelligent\n",
    "    #action = my_intelligent_agent_fn(obs) \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Render the env\n",
    "    env.render()\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.001)\n",
    "   # print(reward)\n",
    "    # If the epsiode is up, then start another one\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba041bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym.spaces.discrete.Discrete"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(env.observation_space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
